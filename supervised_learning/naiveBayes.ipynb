{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes\n",
    "#### assumption that prob of all features are independent of each other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "                      text label\n",
      "0           send money now  spam\n",
      "1       urgent money prize  spam\n",
      "2     you have won a prize  spam\n",
      "3   call me for your prize  spam\n",
      "4        hello how are you   ham\n",
      "5     let us meet tomorrow   ham\n",
      "6  lunch meeting tomorrow?   ham\n",
      "7  congratulations you won   ham\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Sample data: A few emails and their labels\n",
    "data = {\n",
    "    'text': [\n",
    "        'send money now', 'urgent money prize', 'you have won a prize',\n",
    "        'call me for your prize', 'hello how are you', 'let us meet tomorrow',\n",
    "        'lunch meeting tomorrow?', 'congratulations you won'\n",
    "    ],\n",
    "    'label': [\n",
    "        'spam', 'spam', 'spam', 'spam',\n",
    "        'ham', 'ham', 'ham', 'ham'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting text to numbers\n",
    "- each row represent a email \n",
    "- each column represent a word from vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary (Features):\n",
      "['are' 'call' 'congratulations' 'for' 'have' 'hello' 'how' 'let' 'lunch'\n",
      " 'me' 'meet' 'meeting' 'money' 'now' 'prize' 'send' 'tomorrow' 'urgent'\n",
      " 'us' 'won' 'you' 'your']\n",
      "\n",
      "Vectorized Data (Document-Term Matrix):\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      " [0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the text data and transform it into a matrix of token counts\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# You can see the feature names (our vocabulary)\n",
    "print(\"\\nVocabulary (Features):\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# And the vectorized data (sparse matrix)\n",
    "print(\"\\nVectorized Data (Document-Term Matrix):\")\n",
    "print(X_vectorized.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vectorized, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Multinomial Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModel trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00         1\n",
      "        spam       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Email: 'congratulations you have won a cash prize'\n",
      "Predicted Label: **SPAM**\n",
      "\n",
      "Email: 'Can we meet for lunch tomorrow'\n",
      "Predicted Label: **HAM**\n"
     ]
    }
   ],
   "source": [
    "# New emails to classify\n",
    "new_emails = [\n",
    "    \"congratulations you have won a cash prize\", # Should be spam\n",
    "    \"Can we meet for lunch tomorrow\"             # Should be ham\n",
    "]\n",
    "\n",
    "# Transform the new emails using the same vectorizer\n",
    "new_emails_vectorized = vectorizer.transform(new_emails)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_emails_vectorized)\n",
    "\n",
    "# Print the results\n",
    "for email, prediction in zip(new_emails, predictions):\n",
    "    print(f\"\\nEmail: '{email}'\\nPredicted Label: **{prediction.upper()}**\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
