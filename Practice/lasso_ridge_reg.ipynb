{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdafba8b",
   "metadata": {},
   "source": [
    "overfitting happens when the model is too complex and fits the training data too closely helps \n",
    "in making it perform poorly on new data. To avoid this, we use techniques like Lasso and Ridge\n",
    "regression which helps to simplify the model by limiting the size of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e7f6b",
   "metadata": {},
   "source": [
    "#### lasso regression L1\n",
    "\n",
    "- It helps preventing overfitting by penalizing large coefficients which is useful when the number of predictors is large.\n",
    "- It automatically selects most important features by reducing the coefficients of less significant features to zero.\n",
    "- penalty term is added.\n",
    "- Selecting correct lambda value is important. Cross-validation techniques are used to find the optimal value helps in balancing model complexity and predictive performance.\n",
    "\n",
    "#### ridge regression L2\n",
    "\n",
    "- Shrinks all coefficients toward zero, but none become exactly zero.\n",
    "- When there is multicollinearity (high correlation among features) or you want all features to contribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839c9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332c8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ebe73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f6d6b1",
   "metadata": {},
   "source": [
    "##### Ridge Regression with Cross-Validation\n",
    "- Tests 50 values of alpha\n",
    "- Uses 5-fold CV\n",
    "- Chooses the alpha giving the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a89e22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (Ridge): 8.286427728546842\n"
     ]
    }
   ],
   "source": [
    "# Try a range of alpha values\n",
    "alphas = np.logspace(-3, 3, 50)  # 10^-3 to 10^3\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha (Ridge):\", ridge_cv.alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092ccc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge R²: 0.5763294311871543\n",
      "Ridge RMSE: 0.7451051718977542\n"
     ]
    }
   ],
   "source": [
    "y_pred_ridge = ridge_cv.predict(X_test)\n",
    "print(\"Ridge R²:\", r2_score(y_test, y_pred_ridge))\n",
    "print(\"Ridge RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_ridge)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb185744",
   "metadata": {},
   "source": [
    "#### Lasso with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd84265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (Lasso): 0.001\n"
     ]
    }
   ],
   "source": [
    "lasso_cv = LassoCV(alphas=alphas, cv=5, max_iter=10000)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha (Lasso):\", lasso_cv.alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82955fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso R²: 0.5773121026225017\n",
      "Lasso RMSE: 0.7442405630689862\n"
     ]
    }
   ],
   "source": [
    "y_pred_lasso = lasso_cv.predict(X_test)\n",
    "print(\"Lasso R²:\", r2_score(y_test, y_pred_lasso))\n",
    "print(\"Lasso RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lasso)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708d328",
   "metadata": {},
   "source": [
    "##### comparison b/w ridge & lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f7b5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature  Ridge Coeff  Lasso Coeff\n",
      "0      MedInc     0.447339     0.444698\n",
      "1    HouseAge     0.009738     0.009783\n",
      "2    AveRooms    -0.120803    -0.115737\n",
      "3   AveBedrms     0.769052     0.741172\n",
      "4  Population    -0.000002    -0.000002\n",
      "5    AveOccup    -0.003523    -0.003510\n",
      "6    Latitude    -0.419735    -0.418522\n",
      "7   Longitude    -0.433473    -0.431828\n"
     ]
    }
   ],
   "source": [
    "coef_comparison = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Ridge Coeff': ridge_cv.coef_,\n",
    "    'Lasso Coeff': lasso_cv.coef_\n",
    "})\n",
    "print(coef_comparison)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
